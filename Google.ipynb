{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8835b451-d545-4e6f-b52a-810d01f67a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping completed. Data saved to 'image_search_results.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Set up WebDriver with the correct path to your ChromeDriver\n",
    "service = Service('/Users/alankhalili/OneDrive/AI_Computing/chromedriver_mac_arm64/chromedriver')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Google Images\n",
    "driver.get('https://images.google.com')\n",
    "\n",
    "# Wait for the camera icon to be clickable and click on it to search by image\n",
    "camera_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@aria-label=\"Search by image\"]'))\n",
    ")\n",
    "camera_button.click()\n",
    "\n",
    "# Wait for the \"Upload an image\" tab to be clickable and click it\n",
    "upload_tab = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div[3]/form/div[1]/div[1]/div[3]/c-wiz/div[2]/div/div[3]/div[2]/div/div[2]/span'))\n",
    ")\n",
    "upload_tab.click()\n",
    "\n",
    "# Wait for the file input to be visible and upload the image\n",
    "image_input = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//input[@type=\"file\"]'))\n",
    ")\n",
    "image_input.send_keys('/Users/alankhalili/Downloads/bluepants.jpeg')\n",
    "\n",
    "# Allow time for Google to upload and process the image\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll and load more images\n",
    "for _ in range(5):  # Adjust the range if needed to scroll more times\n",
    "    driver.execute_script(\"window.scrollBy(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)  # Adjust sleep time if needed\n",
    "\n",
    "# Use JavaScript to get all image elements\n",
    "image_elements = driver.execute_script(\n",
    "    'return Array.from(document.querySelectorAll(\"img.rg_i.Q4LuWd\")).map(img => img.src);'\n",
    ")\n",
    "\n",
    "# Extracting the URLs from the images and their associated links\n",
    "image_data = []\n",
    "for img_src in image_elements:\n",
    "    try:\n",
    "        img_element = driver.find_element(By.XPATH, f'//img[@src=\"{img_src}\"]')\n",
    "        page_url = img_element.find_element(By.XPATH, '../../a').get_attribute('href')\n",
    "        image_data.append((img_src, page_url))\n",
    "        print(f\"Image URL: {img_src}\")\n",
    "        print(f\"Page URL: {page_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "# Save the scraped data into a CSV file\n",
    "with open('image_search_results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Image URL', 'Page URL'])\n",
    "    writer.writerows(image_data)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed. Data saved to 'image_search_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a08f078-8957-41b7-9101-36d985b5cb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image elements found: 0\n",
      "Scraping completed. Data saved to 'image_search_results.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Set up WebDriver with the correct path to your ChromeDriver\n",
    "service = Service('/Users/alankhalili/OneDrive/AI_Computing/chromedriver_mac_arm64/chromedriver')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Google Images\n",
    "driver.get('https://images.google.com')\n",
    "\n",
    "# Wait for the camera icon to be clickable and click on it to search by image\n",
    "camera_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '//*[@aria-label=\"Search by image\"]'))\n",
    ")\n",
    "camera_button.click()\n",
    "\n",
    "# Wait for the \"Upload an image\" tab to be clickable and click it\n",
    "upload_tab = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div[3]/form/div[1]/div[1]/div[3]/c-wiz/div[2]/div/div[3]/div[2]/div/div[2]/span'))\n",
    ")\n",
    "upload_tab.click()\n",
    "\n",
    "# Wait for the file input to be visible and upload the image\n",
    "image_input = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, '//input[@type=\"file\"]'))\n",
    ")\n",
    "image_input.send_keys('/Users/alankhalili/Downloads/bluepants.jpeg')\n",
    "\n",
    "# Allow time for Google to upload and process the image\n",
    "time.sleep(5)\n",
    "\n",
    "# Attempt to find image elements using a more general approach\n",
    "image_data = []\n",
    "image_elements = driver.find_elements(By.XPATH, '//a[contains(@href, \"imgres?imgurl=\")]')\n",
    "\n",
    "# Debug: Print number of image elements found\n",
    "print(f\"Number of image elements found: {len(image_elements)}\")\n",
    "\n",
    "for element in image_elements:\n",
    "    try:\n",
    "        img_url = element.get_attribute('href').split('imgurl=')[1].split('&')[0]\n",
    "        page_url = element.get_attribute('href').split('imgrefurl=')[1].split('&')[0]\n",
    "        image_data.append((img_url, page_url))\n",
    "        print(f\"Image URL: {img_url}\")\n",
    "        print(f\"Page URL: {page_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "# Save the scraped data into a CSV file\n",
    "with open('image_search_results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Image URL', 'Page URL'])\n",
    "    writer.writerows(image_data)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed. Data saved to 'image_search_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f806cb-d252-489d-9ccc-ab36222ef0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
