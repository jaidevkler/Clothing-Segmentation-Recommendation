{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothing Segmentation using U-Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create DataLoader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to load the dataset, convert the images and masks to tensors, \n",
    "# normalize the images, resize the images and masks, and split the dataset \n",
    "# into train and validation\n",
    "class DatasetLoader():\n",
    "    def __init__(self):\n",
    "      pass\n",
    "\n",
    "    '''\n",
    "      Load images and masks from the dataset\n",
    "\n",
    "      @param images_path - path to the images\n",
    "      @param masks_path - path to the masks\n",
    "      @return train_dataset - train dataset\n",
    "      @return validation_dataset - validation dataset\n",
    "    '''\n",
    "    def load_images_and_masks(self, images_path, masks_path):\n",
    "      image_paths = []\n",
    "      mask_paths = []\n",
    "\n",
    "      # Put the images paths into a list\n",
    "      for root, dir, files in os.walk(images_path):\n",
    "        for file in files:\n",
    "          path = os.path.join(root, file)\n",
    "          image_paths.append(path)\n",
    "\n",
    "      # Put the masks paths into a list\n",
    "      for root, dir, files in os.walk(masks_path):\n",
    "        for file in files:\n",
    "          path = os.path.join(root, file)\n",
    "          mask_paths.append(path)\n",
    "\n",
    "      # Sort the lists into their correct orders\n",
    "      image_paths.sort()\n",
    "      mask_paths.sort()\n",
    "\n",
    "      # Check the length of images and masks\n",
    "      print(\"Number of images: \", len(image_paths))\n",
    "      print(\"Number of masks: \", len(mask_paths))\n",
    "      \n",
    "      # Convert images and masks to tensors\n",
    "      images, masks = self._convert_images_masks_to_tensors(image_paths, mask_paths)\n",
    "\n",
    "      # Normalize images\n",
    "      images = self._normalize_images(images)\n",
    "\n",
    "      # Resize images and masks\n",
    "      images, masks = self._resize_images_and_masks(images, masks)\n",
    "\n",
    "      # Split dataset into train and validation\n",
    "      train_dataset, validation_dataset = self._train_test_split_dataset(images, masks)\n",
    "\n",
    "      return train_dataset, validation_dataset\n",
    "\n",
    "    '''\n",
    "      Convert images and masks to tensors\n",
    "\n",
    "      @param image_paths - list of image paths\n",
    "      @param mask_paths - list of mask paths\n",
    "      @return images - list of images\n",
    "      @return masks - list of masks\n",
    "    '''\n",
    "    def _convert_images_masks_to_tensors(self, image_paths, mask_paths):\n",
    "      images = []\n",
    "      masks = []\n",
    "\n",
    "      # Convert images to tensors\n",
    "      for image in image_paths:\n",
    "        image = tf.io.read_file(image)\n",
    "        image = tf.image.decode_png(image, channels=3, dtype=tf.uint8)\n",
    "        images.append(image)\n",
    "\n",
    "      # Convert masks to tensors\n",
    "      for mask in mask_paths:\n",
    "        mask = tf.io.read_file(mask)\n",
    "        mask = tf.image.decode_png(mask, channels=1, dtype=tf.uint8)\n",
    "        masks.append(mask)\n",
    "\n",
    "      return images, masks\n",
    "\n",
    "    '''\n",
    "      Split dataset into train and validation\n",
    "\n",
    "      @param images - list of images\n",
    "      @param masks - list of masks\n",
    "      @return train_dataset - train dataset\n",
    "      @return validation_dataset - validation dataset\n",
    "    '''\n",
    "    def _train_test_split_dataset(self, images, masks):\n",
    "      train_X, validation_X, train_y, validation_y = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "      # Convert train and validation datasets to tensors\n",
    "      train_X = tf.data.Dataset.from_tensor_slices(train_X)\n",
    "      train_y = tf.data.Dataset.from_tensor_slices(train_y)\n",
    "\n",
    "      # Convert the validation datasets to tensors\n",
    "      validation_X = tf.data.Dataset.from_tensor_slices(validation_X)\n",
    "      validation_y = tf.data.Dataset.from_tensor_slices(validation_y)\n",
    "\n",
    "      # create a 1-1 mapping from X -> y\n",
    "      train_dataset = tf.data.Dataset.zip(train_X, train_y)\n",
    "      validation_dataset = tf.data.Dataset.zip(validation_X, validation_y)\n",
    "\n",
    "      return train_dataset, validation_dataset\n",
    "\n",
    "    '''\n",
    "      Normalize input images\n",
    "\n",
    "      @param images - list of images\n",
    "      @return image_list - list of normalized images\n",
    "    '''\n",
    "    def _normalize_images(self, images):\n",
    "      image_list = []\n",
    "      for image in images:\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = image / 255.0\n",
    "        image_list.append(image)\n",
    "\n",
    "      return image_list\n",
    "\n",
    "    '''\n",
    "      Resize images and masks\n",
    "\n",
    "      @param images - list of images\n",
    "      @param masks - list of masks\n",
    "      @return image_list - list of resized images\n",
    "      @return mask_list - list of resized masks\n",
    "    '''\n",
    "    def _resize_images_and_masks(self, images, masks):\n",
    "      image_list = []\n",
    "      mask_list = []\n",
    "\n",
    "      for image in images:\n",
    "        image = tf.image.resize(image, (384, 384))\n",
    "        image_list.append(image)\n",
    "\n",
    "      for mask in masks:\n",
    "        mask = tf.cast(mask, tf.uint8)\n",
    "        mask = tf.image.resize(mask, (384, 384),\n",
    "                                      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        mask_list.append(mask)\n",
    "\n",
    "      return image_list, mask_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Load, Normalize and Resize image and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "TRAIN_DATASET_PATH = \"Resources/images\"\n",
    "VALIDATION_DATASET_PATH = \"Resources/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DatasetLoader object\n",
    "dataset_loader = DatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set, convert the images and masks to tensors, normalize the images,\n",
    "# resize the images and masks, and split the dataset into train and validation\n",
    "train_dataset, validation_dataset = dataset_loader\\\n",
    "    .load_images_and_masks(TRAIN_DATASET_PATH, VALIDATION_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chek that the train and validation datasets are loadaed correctly\n",
    "print(\"Training Dataset #:\", train_dataset.element_spec)\n",
    "print(\"Training Dataset #:\", validation_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check lentgh of train and validation datasets\n",
    "print(\"Length of train dataset: \", len(train_dataset))\n",
    "print(\"Length of validation dataset: \", len(validation_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Verify the loaded data and masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Create ImageViewer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to vie the images and masks\n",
    "class ImageViewer():\n",
    "    def __init__(self):\n",
    "      pass\n",
    "\n",
    "    '''\n",
    "      Show images and masks from a dataset\n",
    "\n",
    "      @param dataset - dataset to containg images and masks to display\n",
    "      @param num_to_show - an even number of images to show (default is 2)\n",
    "    '''\n",
    "    def show_from_dataset(self, dataset, num_to_show=2):\n",
    "\n",
    "      dataset = dataset.shuffle(100)\n",
    "\n",
    "      for image, mask in dataset.take(5):\n",
    "        plt.figure(figsize=(15,15))\n",
    "        for i in range(num_to_show):\n",
    "          if (i % 2) == 0:\n",
    "            plt.subplot(1,2,i+1)\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "          else:\n",
    "            plt.subplot(1,2,i+1)\n",
    "            plt.imshow(mask, cmap='plasma')\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "    '''\n",
    "      Plot two images side-by-side\n",
    "      @param image1 -image 1\n",
    "      @param image2 - image 2\n",
    "    '''\n",
    "    def plot_two_images(self, image1, image2):\n",
    "      plt.figure(figsize=(15,15))\n",
    "      plt.subplot(1,2, 1)\n",
    "      plt.imshow(image1)\n",
    "      plt.axis('off')\n",
    "\n",
    "      plt.subplot(1,2, 2)\n",
    "      plt.imshow(image2)\n",
    "      plt.axis(\"off\")\n",
    "      plt.show()\n",
    "\n",
    "    '''\n",
    "      Show prediction\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @param pred - prediction\n",
    "    '''\n",
    "    def show_pred(self, image, mask, pred):\n",
    "        plt.figure(figsize=(20,28))\n",
    "\n",
    "        k = 0\n",
    "        for i in pred:\n",
    "            # show the predicted mask\n",
    "            plt.subplot(4,3,1+k*3)\n",
    "            i = tf.argmax(i, axis=-1)\n",
    "            plt.imshow(i, cmap='plasma')\n",
    "            plt.axis('off')\n",
    "            plt.title('Prediction')\n",
    "\n",
    "            # show the groundtruth mask\n",
    "            plt.subplot(4,3,2+k*3)\n",
    "            plt.imshow(mask[k], cmap='plasma')\n",
    "            plt.axis('off')\n",
    "            plt.title('Ground Truth')\n",
    "\n",
    "            # show the real image\n",
    "            plt.subplot(4,3,3+k*3)\n",
    "            plt.imshow(image[k])\n",
    "            plt.axis('off')\n",
    "            plt.title('Actual')\n",
    "            k += 1\n",
    "            if k == 4: break\n",
    "\n",
    "        plt.suptitle('Preditions', color='blue', size=24)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 View Image and correspoding mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image viewer object\n",
    "image_viewer = ImageViewer()\n",
    "# View the images and masks from the train_dataset\n",
    "image_viewer.show_from_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Augment the Images and Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Create an AugmentDataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentDataset():\n",
    "    def __init__(self):\n",
    "      pass\n",
    "\n",
    "    '''\n",
    "      Augment dataset\n",
    "\n",
    "      @param image_dataset - image dataset\n",
    "      @return image_dataset - augmented image dataset\n",
    "    '''\n",
    "    def augment_dataset(self, image_dataset):\n",
    "      a = image_dataset.map(self._brightness)\n",
    "      b = image_dataset.map(self._contrast)\n",
    "      c = image_dataset.map(self._saturation)\n",
    "      d = image_dataset.map(self._hue)\n",
    "      e = image_dataset.map(self._crop)\n",
    "      f = image_dataset.map(self._flip)\n",
    "      g = image_dataset.map(self._rotate)\n",
    "      h = image_dataset.map(self._rotate270)\n",
    "      i = image_dataset.map(self._flip_up_down)\n",
    "      j = image_dataset.map(self._gamma)\n",
    "\n",
    "      # Concatenate all augmented datasets to return a dataset 7X larger\n",
    "      image_dataset = image_dataset.concatenate(a)\n",
    "      image_dataset = image_dataset.concatenate(b)\n",
    "      image_dataset = image_dataset.concatenate(c)\n",
    "      image_dataset = image_dataset.concatenate(d)\n",
    "      image_dataset = image_dataset.concatenate(e)\n",
    "      image_dataset = image_dataset.concatenate(f)\n",
    "      image_dataset = image_dataset.concatenate(g)\n",
    "      image_dataset = image_dataset.concatenate(h)\n",
    "      image_dataset = image_dataset.concatenate(i)\n",
    "      image_dataset = image_dataset.concatenate(j)\n",
    "\n",
    "      return image_dataset\n",
    "\n",
    "    '''\n",
    "      Adjust an image's brightness\n",
    "\n",
    "      @param image - image\n",
    "      @return bright adjusted image\n",
    "    '''\n",
    "    def _brightness(self, image, mask):\n",
    "        image = tf.image.adjust_brightness(image, 0.1)\n",
    "        return image, mask\n",
    "\n",
    "    '''\n",
    "      Adjust an image and mask's contrast\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @return contrast adjusted image\n",
    "      @return contrast adjusted mask\n",
    "    '''\n",
    "    def _contrast(self, image, mask):\n",
    "        image = tf.image.adjust_contrast(image, 0.1)\n",
    "        return image, mask\n",
    "\n",
    "    '''\n",
    "      Adjust an image and mask's saturation\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @return saturation adjusted image\n",
    "      @return saturation adjusted mask\n",
    "    '''\n",
    "    def _saturation(self, image, mask):\n",
    "        image = tf.image.adjust_saturation(image, 0.1)\n",
    "        return image, mask\n",
    "\n",
    "    '''\n",
    "      Adjust an image and mask's hue\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @return hue adjusted image\n",
    "      @return hue adjusted mask\n",
    "    '''\n",
    "    def _hue(self, image, mask):\n",
    "        image = tf.image.adjust_hue(image, 0.1)\n",
    "        return image, mask\n",
    "\n",
    "    '''\n",
    "      Crop an image and mask\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @return cropped image\n",
    "      @return cropped mask\n",
    "    '''\n",
    "    def _crop(self, image, mask):\n",
    "      tf.image.central_crop(image, 0.7)\n",
    "      tf.image.resize(image, (384, 384))\n",
    "\n",
    "      mask = tf.image.central_crop(mask, 0.7)\n",
    "      mask = tf.image.resize(mask, (384,384))\n",
    "      mask = tf.cast(mask, tf.uint8)\n",
    "\n",
    "      return image, mask\n",
    "\n",
    "    '''\n",
    "      Flip an image and mask\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @return flipped image\n",
    "      @return flipped mask\n",
    "    '''\n",
    "    def _flip(self, image, mask):\n",
    "      image = tf.image.flip_left_right(image)\n",
    "      mask = tf.image.flip_left_right(mask)\n",
    "      return image, mask\n",
    "\n",
    "    '''\n",
    "      Rotate an image and mask 90 degress\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @return rotated image\n",
    "      @return rotated mask\n",
    "    '''\n",
    "    def _rotate(self, image, mask):\n",
    "      image = tf.image.rot90(image)\n",
    "      mask = tf.image.rot90(mask)\n",
    "      return image, mask\n",
    "    \n",
    "    '''\n",
    "      Rotate an image and mask 270 degrees\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @return rotated image\n",
    "      @return rotated mask\n",
    "    '''\n",
    "    def _rotate270(self, image, mask):\n",
    "      image = tf.image.rot90(image, -1)\n",
    "      mask = tf.image.rot90(mask, -1)\n",
    "      return image, mask\n",
    "    \n",
    "    '''\n",
    "      Flip an image and mask upside down\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @return flipped image\n",
    "      @return flipped mask\n",
    "    '''\n",
    "    def _flip_up_down(self, image, mask):\n",
    "      image = tf.image.flip_up_down(image)\n",
    "      mask = tf.image.flip_up_down(mask)\n",
    "      return image, mask\n",
    "    \n",
    "    '''\n",
    "      Adjust an image and mask's gamma\n",
    "\n",
    "      @param image - image\n",
    "      @param mask - mask\n",
    "      @return gamma adjusted image\n",
    "      @return gamma adjusted mask\n",
    "    '''\n",
    "    def _gamma(self, image, mask):\n",
    "        image = tf.image.adjust_gamma(image, 0.1)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Augment the images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AugmentDataset object\n",
    "augment_dataset = AugmentDataset()\n",
    "# Augment the train_dataset\n",
    "train_dataset = augment_dataset.augment_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the length of the train_dataset after augmentation\n",
    "print(\"Validation Dataset: \", len(validation_dataset))\n",
    "print(\"Training Dataset: \", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the element spec of the train_dataset to check if the augmentation was successful\n",
    "print(\"Training Dataset #:\", train_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. U-Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Define Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "BATCH = 64\n",
    "AT = tf.data.AUTOTUNE\n",
    "BUFFER = 1000\n",
    "\n",
    "STEPS_PER_EPOCH = 800//BATCH\n",
    "VALIDATION_STEPS = 200//BATCH\n",
    "INITIAL_EPOCHS = 2\n",
    "FINE_TUNE_EPOCHS = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Create Model Builder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Builder Class\n",
    "class ModelBuilder():\n",
    "    def __init__(self):\n",
    "      self.down_sampling_model = None\n",
    "      self.unet_model = None\n",
    "\n",
    "    '''\n",
    "      Create a unet model\n",
    "\n",
    "      @return unet model\n",
    "    '''\n",
    "    def build_unet_model(self):\n",
    "      # create the upsampling model using a combination of upsampling models\n",
    "      upsampling_model = [\n",
    "          self.build_upsampling_model(512, 4),\n",
    "          self.build_upsampling_model(256, 4),\n",
    "          self.build_upsampling_model(128, 4),\n",
    "          self.build_upsampling_model(64, 4)\n",
    "      ]\n",
    "\n",
    "      # create the input layer using the shape of the images\n",
    "      inputs = tf.keras.layers.Input(shape=[384, 384, 3])\n",
    "\n",
    "      self.down_sampling_model = self.build_down_sampling_model()\n",
    "\n",
    "      # store the results of the inputs going through the downsampling model\n",
    "      down_sample = self.down_sampling_model(inputs)\n",
    "\n",
    "      # store the last layer result as an output\n",
    "      output = down_sample[-1]\n",
    "\n",
    "      # store every output from the downsampling layer except the last one\n",
    "      skips = reversed(down_sample[:-1])\n",
    "\n",
    "      # loop through the upsampling model and the skips and concatenate them\n",
    "      for upsample, skip in zip(upsampling_model, skips):\n",
    "        output = upsample(output)\n",
    "        output = tf.keras.layers.Concatenate()([output, skip])\n",
    "\n",
    "      # downsample the output to get 59 mask potential values\n",
    "      output = tf.keras.layers.Conv2DTranspose(\n",
    "          filters=59,\n",
    "          kernel_size=3,\n",
    "          strides=2,\n",
    "          padding='same')(output)\n",
    "\n",
    "      # create and compile the UNET model\n",
    "      self.unet_model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "      self.compile_unet_model()\n",
    "\n",
    "      return self.unet_model\n",
    "\n",
    "    '''\n",
    "      Compile a unet model\n",
    "    '''\n",
    "    def compile_unet_model(self):\n",
    "      self.unet_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    '''\n",
    "      Create a fine-tuned unet model\n",
    "\n",
    "      @return fine-tuned unet model\n",
    "    '''\n",
    "    def build_fine_tuned_unet_model(self):\n",
    "      # enable training for the down_sampling_model (MobileNetV2)\n",
    "      self.down_sampling_model.trainable = True\n",
    "\n",
    "      # recompile the model\n",
    "      self.compile_unet_model()\n",
    "\n",
    "      return self.unet_model\n",
    "\n",
    "    '''\n",
    "      Create a down-sampling model\n",
    "\n",
    "      @return down-sampling model\n",
    "    '''\n",
    "    def build_down_sampling_model(self):\n",
    "      # using MobileNetV2 but any other choice could probably work here\n",
    "      base_model = tf.keras.applications.MobileNetV2(input_shape=(384, 384, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "      # Looking through the MobileNetV2 plot_model I found these blocks that\n",
    "      # fit the needs of the down_sampling_model.\n",
    "      skip_layer_names = [\n",
    "          \"block_1_expand_relu\", # 128 -> 64\n",
    "          \"block_2_expand_relu\", # 64 -> 32\n",
    "          \"block_5_expand_relu\", # 32 -> 16\n",
    "          \"block_8_expand_relu\", # 16 -> 8\n",
    "          \"block_14_expand_relu\", # 8 -> 4\n",
    "      ]\n",
    "\n",
    "      # get the skip layers from the base model using the layer names\n",
    "      skip_layers = [base_model.get_layer(name).output for name in skip_layer_names]\n",
    "\n",
    "      # create the down_sampling model with the base model having training disabled\n",
    "      down_stack = tf.keras.Model(inputs=base_model.input, outputs=skip_layers)\n",
    "      down_stack.trainable = False\n",
    "\n",
    "      return down_stack\n",
    "\n",
    "    '''\n",
    "      Create an up-sampling model\n",
    "\n",
    "      @param filters - number of filters\n",
    "      @param size - size of the kernel\n",
    "      @return up-sampling model\n",
    "    '''\n",
    "    def build_upsampling_model(self, filters, size):\n",
    "      initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "      upsampling_model = tf.keras.Sequential()\n",
    "      upsampling_model.add(tf.keras.layers.Conv2DTranspose(\n",
    "          filters, size, strides=2,\n",
    "          padding='same',\n",
    "          kernel_initializer=initializer,\n",
    "          use_bias=False))\n",
    "\n",
    "      upsampling_model.add(tf.keras.layers.BatchNormalization())\n",
    "      upsampling_model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "      return upsampling_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Build the U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ModelBuilder object\n",
    "model_builder = ModelBuilder()\n",
    "# Build a U-Net model\n",
    "unet_model = model_builder.build_unet_model()\n",
    "# Print the summary of the U-Net model\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache the dataset in memory, shuffle the dataset, batch the dataset into mini-batches and\n",
    "# repeat the dataset (this is used to ensure that the model sees the entire dataset)\n",
    "train_dataset = train_dataset.cache().shuffle(BUFFER).batch(BATCH).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefetch - creates a background thread that preloads data while the model is training\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the validation dataset - This function splits the validation dataset \n",
    "# into mini-batches of size BATCH.\n",
    "validation_dataset = validation_dataset.batch(BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer on train dataset\n",
    "example = next(iter(train_dataset))\n",
    "preds = unet_model(example[0])\n",
    "pred_mask = tf.argmax(preds, axis=-1)\n",
    "pred_mask = tf.expand_dims(pred_mask, -1)\n",
    "\n",
    "pred_mask = pred_mask[0]\n",
    "actual_image = example[0][0]\n",
    "\n",
    "image_viewer.plot_two_images(actual_image, pred_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Train/Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = unet_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=INITIAL_EPOCHS,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    validation_data=validation_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Check the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make a prediction\n",
    "image, mask = next(iter(validation_dataset))\n",
    "pred = unet_model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the image, mask, and prediction\n",
    "image_viewer.show_pred(image, mask, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceReport():\n",
    "    def __init__(self):\n",
    "      self.conf_matrix = None\n",
    "\n",
    "    '''\n",
    "      Plot the UNET model's loss performance\n",
    "\n",
    "      @param model_history - the unet model history\n",
    "    '''\n",
    "    def plot_loss_performance_charts(self, model_history):\n",
    "      loss = model_history.history['loss']\n",
    "      val_loss = model_history.history['val_loss']\n",
    "\n",
    "      plt.figure()\n",
    "      plt.plot(model_history.epoch, loss, 'r', label='Training loss')\n",
    "      plt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\n",
    "      plt.title('Training and Validation Loss')\n",
    "      plt.xlabel('Epoch')\n",
    "      plt.ylabel('Loss Value')\n",
    "      plt.ylim([0.5, 1])\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "    \n",
    "    '''\n",
    "      Plot the UNET model's loss performance - with ploty\n",
    "\n",
    "      @param model_history - the unet model history\n",
    "    '''\n",
    "    def plot_loss_performance_charts_plotly(self, model_history):\n",
    "      loss = model_history.history['loss']\n",
    "      val_loss = model_history.history['val_loss']\n",
    "\n",
    "      fig = go.Figure()\n",
    "\n",
    "      fig.add_trace(go.Scatter(x=model_history.epoch, y=loss,\n",
    "                          mode='lines+markers',\n",
    "                          name='Loss'))\n",
    "\n",
    "      fig.add_trace(go.Scatter(x=history.epoch, y=val_loss,\n",
    "                          mode='lines+markers',\n",
    "                          name='Validation Loss'))\n",
    "\n",
    "      fig.update_layout(title = '<b>Training and Validation Loss',\n",
    "                        title_x=0.5, \n",
    "                        plot_bgcolor='white', \n",
    "                        font=dict(size=10, color=\"grey\"), \n",
    "                        xaxis_title=\"Epochs\",\n",
    "                        yaxis_title=\"Loss Value\")\n",
    "\n",
    "      # Modify x-axis\n",
    "      fig.update_xaxes(\n",
    "          mirror=True,\n",
    "          ticks='outside',\n",
    "          showline=True,\n",
    "          linecolor='lightgrey',\n",
    "          gridcolor='white', \n",
    "          color='grey')\n",
    "\n",
    "      # Modify y-axis\n",
    "      fig.update_yaxes(\n",
    "          mirror=True,\n",
    "          ticks='outside',\n",
    "          showline=True,\n",
    "          linecolor='lightgrey',\n",
    "          gridcolor='lightgrey',\n",
    "          color='grey')\n",
    "\n",
    "      fig.show()\n",
    "\n",
    "    '''\n",
    "      Plot the UNET model's accuracy performance\n",
    "\n",
    "      @param model_history - the unet model history\n",
    "    '''\n",
    "    def plot_accuracy_performance_charts(self, model_history):\n",
    "      accuracy = model_history.history['accuracy']\n",
    "      val_accuracy = model_history.history['val_accuracy']\n",
    "\n",
    "      plt.figure()\n",
    "      plt.plot(model_history.epoch, accuracy, 'r', label='Training Accuracy')\n",
    "      plt.plot(model_history.epoch, val_accuracy, 'bo', label='Validation Accuracy')\n",
    "      plt.title('Training and Validation Accuracy')\n",
    "      plt.xlabel('Epoch')\n",
    "      plt.ylabel('Accuracy Value')\n",
    "      plt.ylim([0.5, 1])\n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "    '''\n",
    "      Plot the UNET model's accuracy performance - with ploty\n",
    "\n",
    "      @param model_history - the unet model history\n",
    "    '''\n",
    "    def plot_accuracy_performance_charts_plotly(self, model_history):\n",
    "      accuracy = model_history.history['accuracy']\n",
    "      val_accuracy = model_history.history['val_accuracy']\n",
    "\n",
    "      fig = go.Figure()\n",
    "\n",
    "      fig.add_trace(go.Scatter(x=model_history.epoch, y=accuracy,\n",
    "                          mode='lines+markers',\n",
    "                          name='Accuracy'))\n",
    "\n",
    "      fig.add_trace(go.Scatter(x=history.epoch, y=val_accuracy,\n",
    "                          mode='lines+markers',\n",
    "                          name='Validation Accuracy'))\n",
    "\n",
    "      fig.update_layout(title = '<b>Training and Validation Accuracy',\n",
    "                        title_x=0.5, \n",
    "                        plot_bgcolor='white', \n",
    "                        font=dict(size=10, color=\"grey\"), \n",
    "                        xaxis_title=\"Epochs\",\n",
    "                        yaxis_title=\"Accuracy Value\")\n",
    "\n",
    "      # Modify x-axis\n",
    "      fig.update_xaxes(\n",
    "          mirror=True,\n",
    "          ticks='outside',\n",
    "          showline=True,\n",
    "          linecolor='lightgrey',\n",
    "          gridcolor='white', \n",
    "          color='grey')\n",
    "\n",
    "      # Modify y-axis\n",
    "      fig.update_yaxes(\n",
    "          mirror=True,\n",
    "          ticks='outside',\n",
    "          showline=True,\n",
    "          linecolor='lightgrey',\n",
    "          gridcolor='lightgrey',\n",
    "          color='grey')\n",
    "\n",
    "      fig.show()\n",
    "\n",
    "    '''\n",
    "      Display a confusion matrix\n",
    "\n",
    "      @param y_true - true labels\n",
    "      @param y_pred - predicted labels\n",
    "    '''\n",
    "    def display_confusion_matrix(self, y_true, y_pred):\n",
    "      self.conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "      # plot the confusion matrix\n",
    "      fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "      ax.matshow(self.conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "      for i in range(self.conf_matrix.shape[0]):\n",
    "          for j in range(self.conf_matrix.shape[1]):\n",
    "              ax.text(x=j, y=i,s=self.conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "      plt.xlabel('Predictions', fontsize=14)\n",
    "      plt.ylabel('Actuals', fontsize=14)\n",
    "      plt.title('Confusion Matrix', fontsize=18)\n",
    "      plt.show()\n",
    "\n",
    "      # Show the confusion matrix results in a text report\n",
    "      self._show_confusion_matrix_report()\n",
    "\n",
    "      '''\n",
    "        Display the results of the confusion matrix as a text report\n",
    "      '''\n",
    "      def _show_confusion_matrix_report(self):\n",
    "        tn, fp, fn, tp = self.conf_matrix.ravel()\n",
    "\n",
    "        print(\"True Positive (TP): \", tp)\n",
    "        print(\"True Negative (TN): \", tn)\n",
    "        print(\"False Positive (FP): \", fp)\n",
    "        print(\"False Negative (FN): \", fn)\n",
    "\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        print(\"\\n\\nMetrics:\")\n",
    "        print(\"Accuracy: \", round(accuracy, 2))\n",
    "        print(\"Precision: \", round(precision, 2))\n",
    "        print(\"Recall: \", round(recall, 2))\n",
    "        print(\"F1-score: \", round(f1_score, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_report = PerformanceReport()\n",
    "performance_report.plot_accuracy_performance_charts_plotly(history)\n",
    "performance_report.plot_loss_performance_charts_plotly(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", history.history['accuracy'][-1])\n",
    "print(\"Loss: \", history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = model_builder.build_fine_tuned_unet_model()\n",
    "\n",
    "history_1 = unet_model.fit(train_dataset,\n",
    "               validation_data=validation_dataset,\n",
    "               steps_per_epoch=STEPS_PER_EPOCH,\n",
    "               validation_steps=VALIDATION_STEPS,\n",
    "               epochs=150,\n",
    "               initial_epoch=50,\n",
    "               verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.7 Checking the predictions - Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = next(iter(validation_dataset))\n",
    "pred = unet_model.predict(image)\n",
    "\n",
    "image_viewer.show_pred(image, mask, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.8 Model Performance - Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_report.plot_accuracy_performance_charts_plotly(history_1)\n",
    "performance_report.plot_loss_performance_charts_plotly(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", history_1.history['accuracy'][-1])\n",
    "print(\"Loss: \", history_1.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save the U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights for later use\n",
    "unet_model.save_weights('../Models/segmentation_model_weights.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later use\n",
    "unet_model.save('../Models/segmentation_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
